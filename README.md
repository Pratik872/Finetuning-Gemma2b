# Finetuning-Gemma2b

## Overview
- LoRA(Low Rank Adaptation) fine tuning of Gemma 2b model on Dolly 15k dataset

- LoRA is a fine-tuning technique which greatly reduces the number of trainable parameters for downstream tasks by freezing the weights of the model and inserting a smaller number of new weights into the model. This makes training with LoRA much faster and more memory-efficient, and produces smaller model weights (a few hundred MBs), all while maintaining the quality of the model outputs.


## Problem Objective
- To fine tune a Large Language model Gemma 2b with Dolly 15k dataset.

## Methodology

The method involves:
- Loading Dataset

- Loading the Large Language model Gemma2b

- Getting completions from the model before fine tuning

- LoRA fine tuning

- Completions after fine tuning the model

### 1 - Dataset
- `Databricks-dolly-15k` is an open source dataset of instruction-following records generated by thousands of Databricks employees in several of the behavioral categories outlined in the InstructGPT paper, including brainstorming, classification, closed QA, generation, information extraction, open QA, and summarization.

- Integrated the application with Groq API

### 2 - Invoking a Large Language model
- Used `Gemma-7b-It` model through Groq. Other free models can also be used

- Prompts would be passed to this model using Groq API

### 3 - Creating a prompt for LLM
- Created a prompt template using `Langchain`

- Defined the prompt to LLM using prompt template

### 4 - Getting transcripts for the video/website using external tools and `Langchain`
- Fetching the URL uploaded by user through streamlit

- Used this URL to get transcripts through `YoutubeLoader` and `UnstructuredURLLoader` in `Langchain` and converting those to data which needs to be passed to the LLM


### Sample Working

![Demo](https://github.com/Pratik872/Youtube-Video-Summarizer/blob/main/readme%20resources/app%20sample.png)


### Built with üõ†Ô∏è
- Packages/Repo : Langchain, Jupyter, Streamlit, Groq

- Coded on : Jupter Notebook (modelling), VSCode(building application)

